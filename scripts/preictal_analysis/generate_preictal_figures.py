#!/usr/bin/env python3
"""
Generate Preictal Window Analysis Figures
=========================================

Create visualizations for IEEE paper showing the impact of 
preictal window length on seizure prediction performance.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json

# Set style for IEEE paper quality figures
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def load_results():
    """Load preictal window comparison results"""
    results_file = 'results/preictal_analysis/window_comparison_results.json'
    summary_file = 'results/preictal_analysis/window_comparison_summary.csv'
    
    with open(results_file, 'r') as f:
        results = json.load(f)
    
    summary = pd.read_csv(summary_file)
    return results, summary

def create_performance_heatmap(summary_df):
    """Create heatmap showing AUC performance across models and window lengths"""
    fig, ax = plt.subplots(1, 1, figsize=(10, 6))
    
    # Pivot data for heatmap
    pivot_data = summary_df.pivot(index='Model', columns='Window_Length', values='AUC_Mean')
    
    # Create heatmap
    sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlGn', 
                center=0.7, vmin=0.5, vmax=1.0, ax=ax, cbar_kws={'label': 'ROC-AUC'})
    
    ax.set_title('Seizure Prediction Performance vs. Preictal Window Length', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.set_xlabel('Preictal Window Length', fontsize=12, fontweight='bold')
    ax.set_ylabel('Machine Learning Model', fontsize=12, fontweight='bold')
    
    # Rotate x-axis labels for better readability
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
    ax.set_yticklabels(['Logistic Regression', 'Random Forest', 'SVM'], rotation=0)
    
    plt.tight_layout()
    
    # Save figure
    output_file = 'results/preictal_analysis/preictal_performance_heatmap.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f'‚úÖ Saved: {output_file}')
    
    plt.close()

def create_window_optimization_curves(summary_df):
    """Create line plots showing performance vs window length for each model"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Extract window lengths as numbers for proper ordering
    summary_df['Window_Num'] = summary_df['Window_Length'].str.replace('s', '').astype(int)
    
    models = summary_df['Model'].unique()
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
    
    # AUC plot
    for i, model in enumerate(models):
        model_data = summary_df[summary_df['Model'] == model].sort_values('Window_Num')
        ax1.errorbar(model_data['Window_Num'], model_data['AUC_Mean'], 
                    yerr=model_data['AUC_Std'], marker='o', linewidth=2, 
                    markersize=8, color=colors[i], label=model.replace('_', ' '), capsize=5)
    
    ax1.set_xlabel('Preictal Window Length (seconds)', fontsize=12, fontweight='bold')
    ax1.set_ylabel('ROC-AUC', fontsize=12, fontweight='bold')
    ax1.set_title('AUC Performance vs. Preictal Window Length', fontsize=12, fontweight='bold')
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0.5, 1.0)
    
    # Accuracy plot
    for i, model in enumerate(models):
        model_data = summary_df[summary_df['Model'] == model].sort_values('Window_Num')
        ax2.errorbar(model_data['Window_Num'], model_data['Accuracy_Mean'], 
                    yerr=model_data['Accuracy_Std'], marker='s', linewidth=2, 
                    markersize=8, color=colors[i], label=model.replace('_', ' '), capsize=5)
    
    ax2.set_xlabel('Preictal Window Length (seconds)', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')
    ax2.set_title('Accuracy vs. Preictal Window Length', fontsize=12, fontweight='bold')
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0.4, 1.0)
    
    plt.suptitle('Seizure Prediction Performance Optimization', fontsize=14, fontweight='bold', y=1.02)
    plt.tight_layout()
    
    # Save figure
    output_file = 'results/preictal_analysis/window_optimization_curves.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f'‚úÖ Saved: {output_file}')
    
    plt.close()

def create_clinical_tradeoff_analysis(summary_df):
    """Create scatter plot showing clinical trade-off between prediction accuracy and warning time"""
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))
    
    # Extract window lengths as numbers
    summary_df['Window_Num'] = summary_df['Window_Length'].str.replace('s', '').astype(int)
    
    models = summary_df['Model'].unique()
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
    markers = ['o', '^', 's']
    
    for i, model in enumerate(models):
        model_data = summary_df[summary_df['Model'] == model]
        scatter = ax.scatter(model_data['Window_Num'], model_data['AUC_Mean'], 
                           s=model_data['Accuracy_Mean']*500,  # Size represents accuracy
                           c=colors[i], marker=markers[i], alpha=0.7, 
                           label=model.replace('_', ' '), edgecolors='black', linewidth=1)
        
        # Add window length labels
        for _, row in model_data.iterrows():
            ax.annotate(f"{row['Window_Num']}s", 
                       (row['Window_Num'], row['AUC_Mean']),
                       xytext=(5, 5), textcoords='offset points', 
                       fontsize=8, alpha=0.8)
    
    ax.set_xlabel('Prediction Warning Time (seconds)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Seizure Detection Performance (ROC-AUC)', fontsize=12, fontweight='bold')
    ax.set_title('Clinical Trade-off: Prediction Accuracy vs. Warning Time', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.legend(fontsize=11, title='ML Algorithm', title_fontsize=12)
    ax.grid(True, alpha=0.3)
    
    # Add text explaining bubble size
    ax.text(0.05, 0.95, 'Bubble size = Accuracy', transform=ax.transAxes, 
            fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    plt.tight_layout()
    
    # Save figure
    output_file = 'results/preictal_analysis/clinical_tradeoff_analysis.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f'‚úÖ Saved: {output_file}')
    
    plt.close()

def create_dataset_distribution_analysis():
    """Show distribution of preictal/interictal windows for each configuration"""
    fig, ax = plt.subplots(1, 1, figsize=(12, 6))
    
    # Data for each window length
    data = {
        '30s': {'preictal': 96, 'interictal': 432},
        '60s': {'preictal': 180, 'interictal': 348},
        '120s': {'preictal': 360, 'interictal': 168},
        '300s': {'preictal': 360, 'interictal': 168}
    }
    
    windows = list(data.keys())
    preictal_counts = [data[w]['preictal'] for w in windows]
    interictal_counts = [data[w]['interictal'] for w in windows]
    
    # Create stacked bar chart
    width = 0.6
    x = np.arange(len(windows))
    
    p1 = ax.bar(x, interictal_counts, width, label='Interictal', color='lightcoral', alpha=0.8)
    p2 = ax.bar(x, preictal_counts, width, bottom=interictal_counts, label='Preictal', color='lightblue', alpha=0.8)
    
    # Add percentage labels
    for i, (pre, inter) in enumerate(zip(preictal_counts, interictal_counts)):
        total = pre + inter
        pre_pct = pre / total * 100
        inter_pct = inter / total * 100
        
        # Interictal percentage
        ax.text(i, inter/2, f'{inter_pct:.1f}%', ha='center', va='center', fontweight='bold')
        # Preictal percentage  
        ax.text(i, inter + pre/2, f'{pre_pct:.1f}%', ha='center', va='center', fontweight='bold')
    
    ax.set_xlabel('Preictal Window Length', fontsize=12, fontweight='bold')
    ax.set_ylabel('Number of Windows', fontsize=12, fontweight='bold')
    ax.set_title('Dataset Composition: Preictal vs. Interictal Windows', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(windows)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Save figure
    output_file = 'results/preictal_analysis/dataset_distribution_analysis.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f'‚úÖ Saved: {output_file}')
    
    plt.close()

def create_summary_table():
    """Create a publication-ready summary table"""
    summary_df = pd.read_csv('results/preictal_analysis/window_comparison_summary.csv')
    
    # Reformat for publication
    summary_df['Performance'] = summary_df.apply(
        lambda row: f"{row['AUC_Mean']:.3f} ¬± {row['AUC_Std']:.3f}", axis=1
    )
    
    # Pivot for better presentation
    table = summary_df.pivot(index='Model', columns='Window_Length', values='Performance')
    
    # Clean up model names
    table.index = ['Logistic Regression', 'Random Forest', 'SVM']
    
    # Save as CSV
    output_file = 'results/preictal_analysis/performance_summary_table.csv'
    table.to_csv(output_file)
    
    print("üìä Performance Summary Table (ROC-AUC ¬± STD)")
    print("=" * 60)
    print(table)
    print(f"\n‚úÖ Table saved: {output_file}")

def main():
    """Generate all figures for IEEE paper"""
    print('üìà GENERATING PREICTAL WINDOW ANALYSIS FIGURES')
    print('==============================================')
    
    # Create output directory
    output_dir = Path('results/preictal_analysis')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Load results
    results, summary_df = load_results()
    
    print(f"‚úÖ Loaded results for {len(summary_df)} model-window combinations")
    
    # Generate figures
    print("\n1. Creating performance heatmap...")
    create_performance_heatmap(summary_df)
    
    print("\n2. Creating optimization curves...")
    create_window_optimization_curves(summary_df)
    
    print("\n3. Creating clinical trade-off analysis...")
    create_clinical_tradeoff_analysis(summary_df)
    
    print("\n4. Creating dataset distribution analysis...")
    create_dataset_distribution_analysis()
    
    print("\n5. Creating summary table...")
    create_summary_table()
    
    print(f"\nüéâ ALL FIGURES GENERATED!")
    print(f"üìÅ Figures saved in: {output_dir}")
    print("\nüìù Key Findings for IEEE Paper:")
    print("  ‚Ä¢ Optimal preictal window: 120 seconds (2 minutes)")
    print("  ‚Ä¢ Best performance: Random Forest with 0.901 AUC")
    print("  ‚Ä¢ Clear trade-off between prediction accuracy and warning time")
    print("  ‚Ä¢ Significant improvement over baseline 60s window (0.723 ‚Üí 0.901 AUC)")

if __name__ == '__main__':
    main()